{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a575d651-f3bf-48e4-9c4d-c7da18e581eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arsenic import browsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae0a94fe-fb93-41f4-aead-5ca4e647d52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mbrowsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBrowser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdefaults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"chrome\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.virtualenvs/web-scraping-with-asyncio-python-BkoSTc6q/lib/python3.9/site-packages/arsenic/browsers.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "browsers.Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d0d4d-e925-4a09-86ab-d19357e3fefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafcc446-d2af-4f3d-9d67-e448331a3bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: structlog in /home/ajay/.virtualenvs/web-scraping-with-asyncio-python-BkoSTc6q/lib/python3.9/site-packages (20.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install structlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "312b2f7c-457c-49b8-a56c-75c4900178e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async_scrape.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile async_scrape.py\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "from arsenic import get_session, keys, browsers, services\n",
    "import pandas as pd\n",
    "from requests_html import HTML\n",
    "import itertools\n",
    "import re\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "import logging\n",
    "import structlog # pip install structlog\n",
    "\n",
    "def set_arsenic_log_level(level = logging.WARNING):\n",
    "    # Create logger\n",
    "    logger = logging.getLogger('arsenic')\n",
    "    \n",
    "    # We need factory, to return application-wide logger\n",
    "    def logger_factory():\n",
    "        return logger\n",
    "    \n",
    "    structlog.configure(logger_factory=logger_factory)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "\n",
    "\n",
    "# /en/fabric/71433-genevieve-floral-by-crystal_walen\n",
    "async def extract_id_slug(url_path):\n",
    "    regex = r\"^[^\\s]+/(?P<id>\\d+)-(?P<slug>[\\w_-]+$\"\n",
    "    group = re.match(regex, url_path)\n",
    "    if not group:\n",
    "        return None, None\n",
    "    return group['id'], group['slug']\n",
    "    \n",
    "    \n",
    "async def get_links(body_content):\n",
    "    html_r = HTML(html=body_content)\n",
    "    fabric_links = [x for x in list(html_r.links) if x.startswith(\"/en/fabric\")]\n",
    "    datas = []\n",
    "    for path in fabric_links:\n",
    "        id_, slug_ = await extract_id_slug(path)\n",
    "        data = {\n",
    "            'id': id_,\n",
    "            'slub': slug_,\n",
    "            'path': path,\n",
    "            'scraped': 0 # True / False -> 1 / 0\n",
    "        }\n",
    "        datas.append(data)\n",
    "        \n",
    "    return datas\n",
    "\n",
    "async def scraper(url):\n",
    "    service = services.Chromedriver()\n",
    "    browser = browsers.Chrome(chromeOptions={\n",
    "        'args': ['--headless', '--disable-gpu']\n",
    "    })\n",
    "    \n",
    "    async with get_session(service, browser) as session:\n",
    "        await session.get(url)\n",
    "        body = await session.get_page_source()\n",
    "        # print(body)\n",
    "        return body\n",
    "    \n",
    "async def store_links_as_df_pickle(datas=[], name='links.pkl'):\n",
    "    df = pd.DataFrame(datas)\n",
    "    df.set_index('id', drop=True, inplace=True)\n",
    "    df.to_pickle(name)\n",
    "    return df\n",
    "\n",
    "    \n",
    "async def run(url):\n",
    "    body_content = await scraper(url)\n",
    "    links = await get_links(body_content)\n",
    "    df = await store_links_as_df_pickle(links)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://www.spoonflower.com/en/shop?on=fabric'\n",
    "    set_arsenic_log_level()\n",
    "    # loop = asyncio.get_event_loop()\n",
    "    # results = loop.run_until_complete(scraper(url))\n",
    "    \n",
    "    df = asyncio.run(run(url))\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cabf3fb4-bdfd-4ccb-a997-9e65404abdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ChromeDriver 98.0.4758.102 (273bf7ac8c909cde36982d27f66f3c70846a3718-refs/branch-heads/4758@{#1151}) on port 57093\n",
      "Only local connections are allowed.\n",
      "Please see https://chromedriver.chromium.org/security-considerations for suggestions on keeping ChromeDriver safe.\n",
      "ChromeDriver was started successfully.\n",
      "2022-06-25 14:06.32 [error    ] error                          data={'error': 'invalid argument', 'message': 'invalid argument: unrecognized capability: chromeOptions', 'stacktrace': '#0 0x55863079dd33 <unknown>\\n#1 0x5586304ff518 <unknown>\\n#2 0x558630515138 <unknown>\\n#3 0x558630556b8b <unknown>\\n#4 0x5586305565c6 <unknown>\\n#5 0x558630557c2d <unknown>\\n#6 0x558630552083 <unknown>\\n#7 0x558630527c0c <unknown>\\n#8 0x558630528cb5 <unknown>\\n#9 0x5586307cb106 <unknown>\\n#10 0x5586307e292d <unknown>\\n#11 0x5586307cd06e <unknown>\\n#12 0x5586307e32b4 <unknown>\\n#13 0x5586307c0e1b <unknown>\\n#14 0x5586307fc908 <unknown>\\n#15 0x5586307fca88 <unknown>\\n#16 0x5586308164c6 <unknown>\\n#17 0x7f0741400609 <unknown>\\n'} message=invalid argument: unrecognized capability: chromeOptions stacktrace=#0 0x55863079dd33 <unknown>\n",
      "#1 0x5586304ff518 <unknown>\n",
      "#2 0x558630515138 <unknown>\n",
      "#3 0x558630556b8b <unknown>\n",
      "#4 0x5586305565c6 <unknown>\n",
      "#5 0x558630557c2d <unknown>\n",
      "#6 0x558630552083 <unknown>\n",
      "#7 0x558630527c0c <unknown>\n",
      "#8 0x558630528cb5 <unknown>\n",
      "#9 0x5586307cb106 <unknown>\n",
      "#10 0x5586307e292d <unknown>\n",
      "#11 0x5586307cd06e <unknown>\n",
      "#12 0x5586307e32b4 <unknown>\n",
      "#13 0x5586307c0e1b <unknown>\n",
      "#14 0x5586307fc908 <unknown>\n",
      "#15 0x5586307fca88 <unknown>\n",
      "#16 0x5586308164c6 <unknown>\n",
      "#17 0x7f0741400609 <unknown>\n",
      " status=400 type=<class 'arsenic.errors.UnknownArsenicError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ajay/upwork/WebScraping/Web-Scraping-Projects/web-scraping-with-asyncio-python/async_scrape.py\", line 85, in <module>\n",
      "    df = asyncio.run(run(url))\n",
      "  File \"/home/ajay/.pyenv/versions/3.9.6/lib/python3.9/asyncio/runners.py\", line 44, in run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"/home/ajay/.pyenv/versions/3.9.6/lib/python3.9/asyncio/base_events.py\", line 642, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/home/ajay/upwork/WebScraping/Web-Scraping-Projects/web-scraping-with-asyncio-python/async_scrape.py\", line 73, in run\n",
      "    body_content = await scraper(url)\n",
      "  File \"/home/ajay/upwork/WebScraping/Web-Scraping-Projects/web-scraping-with-asyncio-python/async_scrape.py\", line 59, in scraper\n",
      "    async with get_session(service, browser) as session:\n",
      "  File \"/home/ajay/.virtualenvs/web-scraping-with-asyncio-python-BkoSTc6q/lib/python3.9/site-packages/arsenic/__init__.py\", line 16, in __aenter__\n",
      "    self.session = await start_session(self.service, self.browser, self.bind)\n",
      "  File \"/home/ajay/.virtualenvs/web-scraping-with-asyncio-python-BkoSTc6q/lib/python3.9/site-packages/arsenic/__init__.py\", line 29, in start_session\n",
      "    return await driver.new_session(browser, bind=bind)\n",
      "  File \"/home/ajay/.virtualenvs/web-scraping-with-asyncio-python-BkoSTc6q/lib/python3.9/site-packages/arsenic/webdriver.py\", line 40, in new_session\n",
      "    status, response = await self.connection.request(\n",
      "  File \"/home/ajay/.virtualenvs/web-scraping-with-asyncio-python-BkoSTc6q/lib/python3.9/site-packages/arsenic/connection.py\", line 55, in wrapper\n",
      "    return await asyncio.get_event_loop().create_task(func(*args, **kwargs))\n",
      "  File \"/home/ajay/.virtualenvs/web-scraping-with-asyncio-python-BkoSTc6q/lib/python3.9/site-packages/arsenic/connection.py\", line 121, in request\n",
      "    check_response_error(data=data, status=response.status)\n",
      "  File \"/home/ajay/.virtualenvs/web-scraping-with-asyncio-python-BkoSTc6q/lib/python3.9/site-packages/arsenic/connection.py\", line 72, in check_response_error\n",
      "    errors.raise_exception(data, status)\n",
      "  File \"/home/ajay/.virtualenvs/web-scraping-with-asyncio-python-BkoSTc6q/lib/python3.9/site-packages/arsenic/errors.py\", line 109, in raise_exception\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "arsenic.errors.UnknownArsenicError: ('invalid argument: unrecognized capability: chromeOptions', None, '#0 0x55863079dd33 <unknown>\\n#1 0x5586304ff518 <unknown>\\n#2 0x558630515138 <unknown>\\n#3 0x558630556b8b <unknown>\\n#4 0x5586305565c6 <unknown>\\n#5 0x558630557c2d <unknown>\\n#6 0x558630552083 <unknown>\\n#7 0x558630527c0c <unknown>\\n#8 0x558630528cb5 <unknown>\\n#9 0x5586307cb106 <unknown>\\n#10 0x5586307e292d <unknown>\\n#11 0x5586307cd06e <unknown>\\n#12 0x5586307e32b4 <unknown>\\n#13 0x5586307c0e1b <unknown>\\n#14 0x5586307fc908 <unknown>\\n#15 0x5586307fca88 <unknown>\\n#16 0x5586308164c6 <unknown>\\n#17 0x7f0741400609 <unknown>\\n')\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7f9100c19580>\n",
      "Unclosed connector\n",
      "connections: ['[(<aiohttp.client_proto.ResponseHandler object at 0x7f9100c11ee0>, 7446.72142332)]']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x7f9100c19670>\n"
     ]
    }
   ],
   "source": [
    "!python3 async_scrape.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ea4bc-1ce0-48e6-a534-37d94ca3b875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
